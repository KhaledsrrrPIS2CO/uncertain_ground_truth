{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7JkMG7MURjP"
      },
      "source": [
        "# MNIST Multi-label MCCP experiments\n",
        "\n",
        "See `README.md` for installation and usage instructions.\n",
        "\n",
        "This notebook shows an example of using Monte Carlo conformal prediction [1] on\n",
        "a synthetic dataset derived from MNIST.\n",
        "\n",
        "```\n",
        "[1] Stutz, D., Roy, A.G., Matejovicova, T., Strachan, P., Cemgil, A.T.,\n",
        "    \u0026 Doucet, A. (2023).\n",
        "    Conformal prediction under ambiguous ground truth. ArXiv, abs/2307.09302.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbiNK2fhURjX"
      },
      "source": [
        "## Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxY5IcV8URjY"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from matplotlib import pyplot as plt\n",
        "import sklearn.neural_network\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjXJUYejURja"
      },
      "outputs": [],
      "source": [
        "import conformal_prediction\n",
        "import monte_carlo\n",
        "import colab_utils\n",
        "import gaussian_toy_dataset as gtd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pp79m0tCURjb"
      },
      "outputs": [],
      "source": [
        "colab_utils.set_style()\n",
        "plot_hist = colab_utils.plot_hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le0rDSsPURjc"
      },
      "source": [
        "## Data\n",
        "\n",
        "We create a synthetic multi-label dataset by overlaying multiple digits in a\n",
        "single image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqXjZjE8URjd"
      },
      "outputs": [],
      "source": [
        "num_examples = 10000\n",
        "ds = tfds.load('mnist', split=f'train[:{num_examples}]').shuffle(\n",
        "    num_examples).batch(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUSUKMOWURje"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "labels = []\n",
        "for b, batch in enumerate(ds):\n",
        "  images.append(jnp.array(batch['image'].numpy()))\n",
        "  labels.append(jnp.array(batch['label'].numpy()))\n",
        "images = jnp.concatenate(images)\n",
        "labels = jnp.concatenate(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk57x_sWURjg"
      },
      "outputs": [],
      "source": [
        "split = num_examples//2\n",
        "combined_images = []\n",
        "combined_labels = []\n",
        "rng = gtd.PRNGSequence(0)\n",
        "r = jax.random.uniform(jax.random.PRNGKey(0), (split,))\n",
        "for n in range(split):\n",
        "  r1 = int(r[n] * 3)\n",
        "  combined_image = jnp.repeat(images[n], 3, axis=2)\n",
        "  combined_image = combined_image.at[:, :, jnp.arange(3) != r1].set(0)\n",
        "  combined_label = jax.nn.one_hot(labels[n], 10)\n",
        "  if labels[n] != labels[split + n]:\n",
        "    r2 = (r1 + 1) % 3\n",
        "    other_image = jnp.repeat(images[split + n], 3, axis=2)\n",
        "    other_image = other_image.at[:, :, jnp.arange(3) != r2].set(0)\n",
        "    combined_image += images[split + n]\n",
        "    combined_label += jax.nn.one_hot(labels[split + n], 10)\n",
        "  combined_images.append(combined_image)\n",
        "  combined_labels.append(combined_label)\n",
        "combined_images = jnp.array(combined_images)\n",
        "combined_labels = jnp.array(combined_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DchqYgz7URjg"
      },
      "outputs": [],
      "source": [
        "split = int((num_examples // 2) * 3/5.)\n",
        "train_images = combined_images[:split]\n",
        "train_labels = combined_labels[:split]\n",
        "held_out_images = combined_images[split:]\n",
        "held_out_labels = combined_labels[split:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECOeGHX7URjh"
      },
      "source": [
        "## Models\n",
        "\n",
        "We train 10 binary models to recognize each digit individually. These will\n",
        "be used to obtain the per-digit conformity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNWwVGS5URji"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for k in range(10):\n",
        "  classifier = sklearn.neural_network.MLPClassifier(alpha=1, max_iter=100)\n",
        "  classifier.fit(\n",
        "      train_images.reshape(train_images.shape[0], -1),\n",
        "      train_labels[:, k])\n",
        "  predictions_k = classifier.predict_log_proba(\n",
        "      held_out_images.reshape(held_out_images.shape[0], -1))\n",
        "  predictions_k = jax.nn.softmax(predictions_k)[:, 1]\n",
        "  predictions.append(predictions_k)\n",
        "predictions = jnp.array(predictions).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeDR-VP4URji"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K92zLiIcURjj"
      },
      "outputs": [],
      "source": [
        "def plot_trials(alpha=0.1, num_trials=10, **kwargs):\n",
        "  \"\"\"Run conformal prediction trials.\"\"\"\n",
        "  rng = jax.random.PRNGKey(0)\n",
        "  coverages = []\n",
        "  sizes = []\n",
        "  for t in range(num_trials):\n",
        "    permutation_rng, mc_rng, rng = jax.random.split(rng, 3)\n",
        "    split = int((num_examples // 2) * 2/5.) // 2\n",
        "    permutation = jax.random.permutation(permutation_rng, 2 * split)\n",
        "    val_labels = held_out_labels[permutation[:split]]\n",
        "    val_predictions = predictions[permutation[:split]]\n",
        "    test_images = held_out_images[permutation[split:]]\n",
        "    test_labels = held_out_labels[permutation[split:]]\n",
        "    test_predictions = predictions[permutation[split:]]\n",
        "\n",
        "    num_classes = val_predictions.shape[1]\n",
        "    mc_val_predictions, mc_val_labels = monte_carlo.sample_mc_labels(\n",
        "        mc_rng, val_predictions, val_labels, 10)\n",
        "    mc_val_predictions = mc_val_predictions.reshape(-1, num_classes)\n",
        "    mc_val_labels = mc_val_labels.reshape(-1)\n",
        "\n",
        "    p_values = conformal_prediction.compute_p_values(\n",
        "        mc_val_predictions, mc_val_labels, test_predictions)\n",
        "    confidence_sets = (p_values \u003e= alpha).astype(int)\n",
        "    coverages.append(jnp.sum(\n",
        "        test_labels * confidence_sets, axis=1) / jnp.sum(test_labels, axis=1))\n",
        "    sizes.append(jnp.sum(confidence_sets, axis=1))\n",
        "  coverages = jnp.array(coverages)\n",
        "  sizes = jnp.array(sizes)\n",
        "\n",
        "  hist, _ = colab_utils.plot_hist(jnp.mean(coverages, axis=1), normalize=True)\n",
        "  plt.vlines(1 - alpha, 0, jnp.max(hist), color='black', label='Target')\n",
        "  plt.title('Aggregated coverage for multi-label classification')\n",
        "  plt.xlabel('Empirical coverage')\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.legend()\n",
        "  plt.gcf().set_size_inches(kwargs.get('width', 5), kwargs.get('height', 3))\n",
        "  plt.savefig('mnist_mccp_coverage.pdf', bbox_inches=\"tight\")\n",
        "  plt.show()\n",
        "  %download_file mnist_mccp_coverage.pdf\n",
        "\n",
        "  hist, _ = colab_utils.plot_hist(\n",
        "      jnp.mean(sizes, axis=1), normalize=True, label='Inefficiency')\n",
        "  plt.vlines(\n",
        "      jnp.mean(sizes), 0, jnp.max(hist),\n",
        "      label=f'Average: {jnp.mean(sizes):.2f}', color='black')\n",
        "  plt.title('Inefficiency histogram')\n",
        "  plt.xlabel('Inefficiency')\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.legend()\n",
        "  plt.gcf().set_size_inches(kwargs.get('width', 5), kwargs.get('height', 3))\n",
        "  plt.savefig('mnist_mccp_ineff.pdf', bbox_inches=\"tight\")\n",
        "  plt.show()\n",
        "  %download_file mnist_mccp_ineff.pdf\n",
        "\n",
        "  alpha = 0.1\n",
        "  for n in range(3):\n",
        "    plt.bar(jnp.arange(10), test_labels[n], alpha=0.5, label='Labels')\n",
        "    plt.bar(jnp.arange(10), p_values[n], alpha=0.5, label='p-values')\n",
        "    plt.hlines(alpha, -0.5, 9.5, label='Confidence level', color='red')\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "    plt.xlabel('Class')\n",
        "    plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "    plt.gcf().set_size_inches(\n",
        "        kwargs.get('width', 3), kwargs.get('height', 1.25))\n",
        "    plt.savefig(f'mnist_example{n}.pdf', bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    %download_file mnist_example{n}.pdf\n",
        "\n",
        "    plt.imshow(test_images[n] / 255.)\n",
        "    plt.axis('off')\n",
        "    plt.gcf().set_size_inches(kwargs.get('width', 2), kwargs.get('height', 2))\n",
        "    plt.savefig(f'mnist_sets{n}.pdf', bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "    %download_file mnist_sets{n}.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6d83xEcURjk"
      },
      "outputs": [],
      "source": [
        "plot_trials(alpha=0.1, num_trials=500)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
