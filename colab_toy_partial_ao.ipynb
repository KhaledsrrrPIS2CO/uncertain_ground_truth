{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuukhcFxUC6Z"
      },
      "source": [
        "# Uncertainty-adjusted accuracy evaluation\n",
        "\n",
        "See `README.md` for installation and usage instructions.\n",
        "\n",
        "This notebook shows an example of using the partial average overlap\n",
        "implementation of [2] on the dataset of [1].\n",
        "\n",
        "```\n",
        "[1] Stutz, D., Roy, A.G., Matejovicova, T., Strachan, P., Cemgil, A.T.,\n",
        "    \u0026 Doucet, A. (2023).\n",
        "    Conformal prediction under ambiguous ground truth. ArXiv, abs/2307.09302.\n",
        "[2] Stutz, D., Cemgil, A.T., Roy, A.G., Matejovicova, T., Barsbey, M.,\n",
        "    Strachan, P., Schaekermann, M., Freyberg, J.V., Rikhye, R.V., Freeman, B.,\n",
        "    Matos, J.P., Telang, U., Webster, D.R., Liu, Y., Corrado, G.S., Matias, Y.,\n",
        "    Kohli, P., Liu, Y., Doucet, A., \u0026 Karthikesalingam, A. (2023).\n",
        "    Evaluating AI systems under uncertain ground truth: a case study in\n",
        "    dermatology. ArXiv, abs/2307.02191.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EY62HMyaUC6l"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "import matplotlib\n",
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skKpu2ySUC6q"
      },
      "outputs": [],
      "source": [
        "import ranking_metrics\n",
        "import colab_utils\n",
        "import formats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7ptcO3jUC6s"
      },
      "outputs": [],
      "source": [
        "with open('toy_data.pkl', 'rb') as f:\n",
        "  data = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsd2QjwGUC6t"
      },
      "outputs": [],
      "source": [
        "with open(f'toy_predictions0.pkl', 'rb') as f:\n",
        "  model_predictions = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOzsEWqYUC6v"
      },
      "outputs": [],
      "source": [
        "model_rankings = jnp.argsort(model_predictions, axis=1)\n",
        "model_groups = jnp.array([jnp.arange(model_rankings.shape[1]) for _ in model_rankings])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW4yQbFTUC6w"
      },
      "outputs": [],
      "source": [
        "num_examples = 10\n",
        "assert num_examples \u003e 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G9OVlVeUC6y"
      },
      "outputs": [],
      "source": [
        "for i, selector in enumerate(data['test_selectors'][:num_examples]):\n",
        "  print('Example ', i, ', annotation 0: ', selector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7OLjXAfUC60"
      },
      "outputs": [],
      "source": [
        "model_selectors = formats.convert_rankings_to_selectors(\n",
        "    model_rankings[:num_examples].reshape(num_examples, 1, -1),\n",
        "    model_groups[:num_examples].reshape(num_examples, 1, -1))\n",
        "for i, selector in enumerate(model_selectors):\n",
        "  print('Example ', i, ', model prediction: ', selector[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Lra56ZGUC62"
      },
      "outputs": [],
      "source": [
        "ranking_metrics.average_overlap(\n",
        "    model_rankings[:num_examples],\n",
        "    data['test_rankings'][:num_examples, 0],\n",
        "    jnp.sum(data['test_groups'][:num_examples, 0] \u003e= 0, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy-GTJHgUC64"
      },
      "outputs": [],
      "source": [
        "ranking_metrics.partial_average_overlap(\n",
        "    model_rankings[:num_examples],\n",
        "    model_groups[:num_examples],\n",
        "    data['test_rankings'][:num_examples, 0],\n",
        "    data['test_groups'][:num_examples, 0],\n",
        "    jnp.sum(data['test_groups'][:num_examples, 0] \u003e= 0, axis=1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
